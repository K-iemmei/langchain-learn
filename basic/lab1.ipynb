{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bead651b",
   "metadata": {},
   "source": [
    "#### 1. Getting up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99698862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and setup environment\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install langchain-google-genai \n",
    "!pip install langchain-community \n",
    "!pip install langchain-text-splitters  \n",
    "!export OPENAI_API_KEY=\"your-openai-api-key\" \n",
    "!export GOOGLE_API_KEY=\"your-google-api-key\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa38f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1114947",
   "metadata": {},
   "source": [
    "#### 2. Using LLMs in LangChain "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14f9da",
   "metadata": {},
   "source": [
    "Useful parameters to configure llms \n",
    "* __temperature__ : lower value produce more predictable output and higher value generate more creative, unexpected.   \n",
    "* __max_token__ : Limit size(and cost) of the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebe0fe1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Donald John Trump (born 1946) is an American businessman, television personality, and politician who served as the **45th President of the United States from 2017 to 2021**.\\n\\nHere\\'s a breakdown of his background and career:\\n\\n1.  **Early Life and Business Career:**\\n    *   Born in Queens, New York City, he inherited a real estate business from his father, Fred Trump.\\n    *   He expanded it into a global empire, developing hotels, casinos, golf courses, and other properties under the Trump Organization.\\n    *   He also became a prominent media figure, particularly known for hosting the reality television show \"The Apprentice\" for over a decade, which significantly boosted his public profile.\\n\\n2.  **Political Career and Presidency (2017-2021):**\\n    *   Trump\\'s political career began with his successful campaign for president in 2016, running as a Republican. His campaign was characterized by populist rhetoric, promises to \"Make America Great Again,\" and a focus on issues like immigration control (including building a wall on the U.S.-Mexico border), trade protectionism, and deregulation.\\n    *   During his presidency, he signed the Tax Cuts and Jobs Act of 2017, appointed three conservative justices to the Supreme Court, withdrew the U.S. from the Paris Agreement on climate change and the Iran nuclear deal, and initiated trade disputes with China.\\n    *   He faced an impeachment inquiry in 2019 and a second one in 2021, both resulting in acquittal by the Senate.\\n    *   He lost his bid for re-election in 2020 to Democrat Joe Biden, making unsubstantiated claims of widespread electoral fraud following the election.\\n\\n3.  **Post-Presidency:**\\n    *   Since leaving office, Trump has remained a highly influential figure in the Republican Party.\\n    *   He has continued to hold rallies, endorse candidates, and has announced his candidacy for the 2024 presidential election.\\n\\nThroughout his career, Trump has been a polarizing and often controversial figure, and his presidency and public persona have had a significant and lasting impact on American politics and culture.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--63d8b45d-8758-4a7a-9f86-dcf6a3d64a9b-0', usage_metadata={'input_tokens': 5, 'output_tokens': 1653, 'total_tokens': 1658, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1179}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Google Gemini 2.5 Flash with LangChain \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0)\n",
    "\n",
    "llm.invoke(\"Who is Trump ?\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa199d22",
   "metadata": {},
   "source": [
    "Some LLM provider (OpenAI) differentiate message to 3 roles: \n",
    "\n",
    "* __system role__ : used for instruction the model should to do\n",
    "\n",
    "* __user role__ : used for the user'query and any other content produce by user\n",
    "\n",
    "* __assistant role__ : used for content generated by the model\n",
    "\n",
    "Alternatively, ChatModel make use of different type of chat message interfaces associated with each role: \n",
    "\n",
    "* __HumanMessage__ \n",
    "* __AIMessasge__ \n",
    "* __SystemMessage__ \n",
    "* __ChatMessage__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bd08d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Paris!!!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--7a3331d0-f9f0-4be7-a3fd-4480b0e14bf6-0', usage_metadata={'input_tokens': 35, 'output_tokens': 34, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 32}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "systemMsg = SystemMessage(\n",
    "    '''\n",
    "    You are a helpful assistant that response to questions with \n",
    "    three exclamation marks at the end.\n",
    "    '''\n",
    ")\n",
    "humanMsg = HumanMessage(\n",
    "    '''\n",
    "    What is capital of France?\n",
    "    '''\n",
    ")\n",
    "\n",
    "llm.invoke([systemMsg, humanMsg])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba32bac",
   "metadata": {},
   "source": [
    "#### 3. Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e9c44b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I don't know\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'} id='lc_run--09a8f3f3-29cc-48d3-9c65-8ee853fcc2ab-0' usage_metadata={'input_tokens': 66, 'output_tokens': 195, 'total_tokens': 261, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 190}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate \n",
    "\n",
    "template = PromptTemplate.from_template( \n",
    "    \"\"\"\n",
    "    You are a helpful assistant that response to questions based on the given context.\n",
    "    If cant answer based on the context, say \"I don't know\".\n",
    "\n",
    "    Context: {context} \n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\",\n",
    ")\n",
    "prompt = template.invoke(\n",
    "    {\n",
    "        \"context\": \"The capital of France is Paris.\",\n",
    "        \"question\": \"What is the capital of VietNam?\"\n",
    "    }\n",
    ")   \n",
    "completion = llm.invoke(prompt)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be47356c",
   "metadata": {},
   "source": [
    "#### 4.Specific Formats out of LLMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09025be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerFormat(answer='They both weigh the same.', justification='A pound of bricks weighs one pound, and a pound of feathers also weighs one pound. The weight is the same, only the density and volume differ.')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define Format Structures \n",
    "# Example: JSON Format \n",
    "from langchain_core.utils.pydantic import BaseModel, Field \n",
    "\n",
    "class AnswerFormat(BaseModel):\n",
    "    ''' Answer to the user's question along with justification for the answer.'''\n",
    "    answer: str\n",
    "    \"\"\"The answer to the user's question.\"\"\"\n",
    "\n",
    "    justification: str\n",
    "    \"\"\"The justification for the answer.\"\"\" \n",
    "\n",
    "structured_llm = llm.with_structured_output(AnswerFormat)\n",
    "structured_llm.invoke(\"\"\"What weighs morre, a pound of bricks or a pound of feathers?\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d2c0d",
   "metadata": {},
   "source": [
    "#### 5. Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab627de",
   "metadata": {},
   "source": [
    "* __invoke__ transforms a single input into an output \n",
    "* __batch__ efficiently transform multiple input into multiple output \n",
    "* __stream__ stream output from a single input ass it's produced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "733ce184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoke:  content=\"There are 10 types of people in the world: those who understand binary, and those who don't.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'} id='lc_run--76367ec3-af49-458e-9455-7ceabe5c7653-0' usage_metadata={'input_tokens': 8, 'output_tokens': 1221, 'total_tokens': 1229, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1197}}\n",
      "Batch:  [AIMessage(content=\"There are 10 types of people in the world: those who understand binary, and those who don't.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--c7bf3f63-96dc-414f-b34f-b699892d49eb-0', usage_metadata={'input_tokens': 8, 'output_tokens': 1221, 'total_tokens': 1229, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1197}}), AIMessage(content='Why did the cat sit on the computer?\\n\\nTo keep an eye on the mouse!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--7f3bfc46-d844-4fbc-964d-58088734e2fe-0', usage_metadata={'input_tokens': 8, 'output_tokens': 296, 'total_tokens': 304, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 278}}), AIMessage(content=\"Why did the dog sit in the shade?\\n\\nBecause he didn't want to be a hot dog!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--fcac74ad-f9e8-4a70-8a8a-6d3acc108ca0-0', usage_metadata={'input_tokens': 8, 'output_tokens': 215, 'total_tokens': 223, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 193}})]\n",
      "Stream:  "
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0) \n",
    "\n",
    "comlpetion = llm.invoke(\"Tell me a joke about programming.\")\n",
    "print(\"Invoke: \", comlpetion) \n",
    "completions = llm.batch(\n",
    "    [\n",
    "        \"Tell me a joke about programming.\",\n",
    "        \"Tell me a joke about cats.\",\n",
    "        \"Tell me a joke about dogs.\",\n",
    "    ]\n",
    ")       \n",
    "print(\"Batch: \", completions) \n",
    "completion_stream = llm.stream(\"Tell me a joke about AI.\")\n",
    "print(\"Stream: \", end=\" \")      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c865f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
